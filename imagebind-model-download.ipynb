{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import data\n",
    "import torch\n",
    "from models import imagebind_model\n",
    "from models.imagebind_model import ModalityType\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = imagebind_model.imagebind_huge(pretrained=True)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Instantiate model\n",
    "model = imagebind_model.imagebind_huge(pretrained=True)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list=[\"A dog.\", \"A cat\", \"A bird\"]\n",
    "image_paths=[\"sample_images/dog_image.jpg\", \"sample_images/cat_image.jpg\", \"sample_images/bird_image.jpg\"]\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = imagebind_model.imagebind_huge(pretrained=True)\n",
    "\n",
    "# Load data\n",
    "inputs = {\n",
    "    ModalityType.TEXT: data.load_and_transform_text(text_list, device),\n",
    "    ModalityType.VISION: data.load_and_transform_vision_data(image_paths, device),\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    embeddings = model(inputs)\n",
    "\n",
    "print(embeddings[ModalityType.VISION])\n",
    "print(embeddings[ModalityType.TEXT])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
