{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "pinecone = Pinecone(\n",
    "   api_key = os.getenv['PINECONE_API_KEY']\n",
    ")\n",
    "\n",
    "pinecone = Pinecone(\n",
    "   api_key = os.getenv['PINECONE_API_KEY']\n",
    ")\n",
    "\n",
    "my_index_name = \"pinterest-multimodal-search\"\n",
    "my_index = pinecone.Index(name = my_index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the imagebind modal\n",
    "from models import data\n",
    "import torch\n",
    "from models import imagebind_model\n",
    "from models.imagebind_model import ModalityType\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = imagebind_model.imagebind_huge(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Textto Image\n",
    "query = \"blue jeans with 4 pockets\"\n",
    "inputs = {\n",
    "            ModalityType.TEXT: data.load_and_transform_text(query, device)\n",
    "        }\n",
    "\n",
    "with torch.no_grad():\n",
    "    embeddings = model(inputs)\n",
    "\n",
    "query_embedding = embeddings[ModalityType.TEXT].numpy()\n",
    "result = my_index.query(vector=query_embedding.tolist()[0], top_k=topk, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(topk):\n",
    "    img_url = result['matches'][i]['metadata']['image_url']\n",
    "    response = requests.get(img_url)\n",
    "    if response.status_code == 200:\n",
    "        # Read the image from the response content\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        # Display the image\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')  # Turn off axis\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Failed to fetch image from URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Image to Image\n",
    "# Using Images\n",
    "img_query = ['images/f68b296900cc4166c7e2dde9445fc8fd.jpg']\n",
    "inputs = {\n",
    "            ModalityType.VISION: data.load_and_transform_vision_data(img_query, device)\n",
    "        }\n",
    "\n",
    "with torch.no_grad():\n",
    "    embeddings = model(inputs)\n",
    "\n",
    "query_embedding = embeddings[ModalityType.VISION].numpy()\n",
    "result = my_index.query(vector=query_embedding.tolist()[0], top_k=3, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(topk):\n",
    "    img_url = result['matches'][i]['metadata']['image_url']\n",
    "    response = requests.get(img_url)\n",
    "    if response.status_code == 200:\n",
    "        # Read the image from the response content\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        # Display the image\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')  # Turn off axis\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Failed to fetch image from URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio to Image\n",
    "import torchaudio\n",
    "platform = torchaudio.get_audio_backend()\n",
    "\n",
    "if platform == 'sox' or platform == 'sox_io':\n",
    "    # Set the backend to 'sox_io' on Linux/macOS\n",
    "    torchaudio.set_audio_backend('sox_io')\n",
    "elif platform == 'soundfile':\n",
    "    # Set the backend to 'soundfile' on Windows\n",
    "    torchaudio.set_audio_backend('soundfile')\n",
    "else:\n",
    "    # Handle unsupported platforms or cases where no backend is available\n",
    "    print(\"No suitable audio backend available for the current platform.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio to Image models\n",
    "from models import data\n",
    "import torch\n",
    "from models.imagebind_model import ModalityType\n",
    "audio_query = ['audio/blue_jeans_1.wav']\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "inputs = {\n",
    "            ModalityType.AUDIO: data.load_and_transform_audio_data(audio_query, device)\n",
    "        }\n",
    "\n",
    "with torch.no_grad():\n",
    "    embeddings = model(inputs)\n",
    "\n",
    "query_embedding = embeddings[ModalityType.AUDIO].numpy()\n",
    "result = my_index.query(vector=query_embedding.tolist()[0], top_k=5, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(topk):\n",
    "    img_url = result['matches'][i]['metadata']['image_url']\n",
    "    response = requests.get(img_url)\n",
    "    if response.status_code == 200:\n",
    "        # Read the image from the response content\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        # Display the image\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')  # Turn off axis\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Failed to fetch image from URL\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newwww",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
