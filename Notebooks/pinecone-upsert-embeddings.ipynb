{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import data\n",
    "import torch\n",
    "from models import imagebind_model\n",
    "from models.imagebind_model import ModalityType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 3\n",
    "my_index_name = \"pinterest-multimodal-search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = imagebind_model.imagebind_huge(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def download_image(url, save_directory):\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "    print(url)\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            # Extract the filename from the URL\n",
    "            filename = url.split(\"/\")[-1]\n",
    "            save_path = os.path.join(save_directory, filename)\n",
    "        \n",
    "            with open(save_path, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            return save_path\n",
    "        else:\n",
    "            return \"\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_image_embeddings(df, save_directory):\n",
    "    from models import data\n",
    "    import pickle\n",
    "    import os\n",
    "    df['text_embeddings'] = None \n",
    "    df['image_embeddings'] = None\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        print(i)\n",
    "        text_description = [row['image_description']]\n",
    "        image_path = download_image(row['image_url'], save_directory)\n",
    "        if image_path:\n",
    "            inputs = {\n",
    "                ModalityType.TEXT: data.load_and_transform_text(text_description, device),\n",
    "                ModalityType.VISION: data.load_and_transform_vision_data([image_path], device),\n",
    "            }\n",
    "\n",
    "            with torch.no_grad():\n",
    "                embeddings = model(inputs)\n",
    "            \n",
    "            text_embedding = embeddings[ModalityType.TEXT].numpy()\n",
    "            print(text_embedding.shape)\n",
    "            image_embedding = embeddings[ModalityType.VISION].numpy()\n",
    "            print(image_embedding.shape)\n",
    "            df.at[i, 'text_embeddings'] = text_embedding\n",
    "            df.at[i, 'image_embeddings'] = image_embedding\n",
    "\n",
    "            os.remove(image_path)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    df['text_embeddings'] = df['text_embeddings'].astype(object)\n",
    "    df['image_embeddings'] = df['image_embeddings'].astype(object)\n",
    "\n",
    "    with open('data/ImageBind_multimodal_pinterestData_embeddings', 'wb') as file:\n",
    "        pickle.dump(df, file)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the pinterest-fashion-dataset.csv from here https://www.kaggle.com/datasets/samikshakolhe/pinterest-fashion-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pinterest-fashion-dataset.csv')\n",
    "save_directory = 'images/'\n",
    "new_df = get_text_image_embeddings(df, save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the pickle file which contains image embddings\n",
    "with open('data/ImageBind_multimodal_pinterestData_embeddings', 'rb') as file:\n",
    "      image_data_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinecone Connect\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "print(type(image_data_df['image_embeddings'].iloc[0]))\n",
    "pinecone = Pinecone(\n",
    "   api_key = os.getenv['PINECONE_API_KEY']\n",
    ")\n",
    "\n",
    "vector_dim = image_data_df.image_embeddings[0].shape[1]\n",
    "print(vector_dim)\n",
    "if my_index_name not in pinecone.list_indexes():\n",
    " # Create the vectors dimension\n",
    " pinecone.create_index(name = my_index_name,\n",
    "                       dimension=vector_dim,\n",
    "                       metric=\"cosine\",\n",
    "                       spec=ServerlessSpec(\n",
    "                        cloud=\"aws\",\n",
    "                        region=\"us-east-1\"\n",
    "                        ))\n",
    "# Connect to the index\n",
    "my_index = pinecone.Index(name = my_index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_upsert(data):\n",
    "    upsert_list = []\n",
    "    for index, (id_, values, metadata) in enumerate(data):\n",
    "        entry = {\n",
    "            \"id\": id_,\n",
    "            \"values\": [val for sublist in values for val in sublist],\n",
    "            \"metadata\": metadata\n",
    "        }\n",
    "        upsert_list.append(entry)\n",
    "    return upsert_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert Image Embeddings into the Pinecone\n",
    "\n",
    "image_data_df = image_data_df.dropna(subset=['image_embeddings'])\n",
    "image_data_df[\"vector_id\"] = image_data_df.index\n",
    "image_data_df[\"vector_id\"] = image_data_df[\"vector_id\"].apply(str)\n",
    "print(type(image_data_df.iloc[0].age))\n",
    "\n",
    "# Get all the metadata\n",
    "final_metadata = []\n",
    "for index in range(len(image_data_df)):\n",
    " final_metadata.append({\n",
    "     'ID':  index,\n",
    "     'user_name': image_data_df.iloc[index].user_name,\n",
    "     'age': int(image_data_df.iloc[index].age),\n",
    "     'gender': image_data_df.iloc[index].gender,\n",
    "     'category' : image_data_df.iloc[index].category,\n",
    "     'brand': image_data_df.iloc[index].brand,\n",
    "     'image_url': image_data_df.iloc[index].image_url\n",
    " })\n",
    "image_IDs = image_data_df.vector_id.tolist()\n",
    "image_embeddings = [arr.tolist() for arr in image_data_df.image_embeddings.tolist()]\n",
    "# # Create the single list of dictionary format to insert\n",
    "data_to_upsert = list(zip(image_IDs, image_embeddings, final_metadata))\n",
    "data_to_upsert = convert_to_upsert(data_to_upsert)\n",
    "# # Upload the final data\n",
    "\n",
    "def chunks(lst, chunk_size):\n",
    "    for i in range(0, len(lst), chunk_size):\n",
    "        yield lst[i:i + chunk_size]\n",
    "\n",
    "with pinecone.Index(my_index_name, pool_threads=30) as index:\n",
    "   # Send requests in parallel\n",
    "   async_results = [\n",
    "       index.upsert(vectors=ids_vectors_chunk, async_req=True)\n",
    "       for ids_vectors_chunk in chunks(data_to_upsert, chunk_size=100)\n",
    "   ]\n",
    "   # Wait for and retrieve responses (this raises in case of error)\n",
    "   [async_result.get() for async_result in async_results]\n",
    "# my_index.upsert(vectors = data_to_upsert)\n",
    "\n",
    "my_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodel_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
